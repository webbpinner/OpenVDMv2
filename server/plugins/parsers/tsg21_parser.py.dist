# =================================================================================== #
#
#         FILE:  tsg21_parser.py
#
#        USAGE:  tsg21_parser.py [-h] [-v+] [--timeFormat] [--startDT] [--stopDT] <dataFile>
#
#  DESCRIPTION:  Parse the supplied SBE21 TSG data and return the json-formatted
#                string used by OpenVDM as part of it's Data dashboard.
#
#      OPTIONS:  [-h] Return the help message.
#                [-v] Increase verbosity (default: warning)
#                [--timeFormat] date/time format to use when parsing datafile, default
#                               yyyy-mm-ddTHH:MM:SS.sssZ
#                [--startTS] optional start crop time (strptime format)
#                [--stopTS] optional stop crop time (strptime format)
#                <dataFile> Full or relative path of the data file to process.
#
# REQUIREMENTS:  Python3.8
#                Python Modules:
#                    numpy==1.19.5
#                    pandas==1.2.0
#                    PyYAML==5.3.1
#                    requests==2.25.1
#
#         BUGS:
#        NOTES:
#       AUTHOR:  Webb Pinner
#      COMPANY:  Capable Solutions
#      VERSION:  2.5
#      CREATED:  2016-08-29
#     REVISION:  2021-01-17
#
# LICENSE INFO:  Open Vessel Data Management v2.5 (OpenVDMv2)
#                Copyright (C) 2021 OceanDataRat.org
#
#    This program is free software: you can redistribute it and/or modify it under the
#    terms of the GNU General Public License as published by the Free Software
#    Foundation, either version 3 of the License, or (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful, but WITHOUT ANY
#    WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
#    PARTICULAR PURPOSE.  See the GNU General Public License for more details.
#
#    You should have received a copy of the GNU General Public License #    along with
#    this program.  If not, see <http://www.gnu.org/licenses/>.
#
# =================================================================================== #

import os
import sys
import csv
import copy
import json
import pandas as pd
import numpy as np
import argparse
import logging
from datetime import datetime

from os.path import dirname, realpath
sys.path.append(dirname(dirname(dirname(dirname(realpath(__file__))))))

from server.lib.openvdm_plugin import OpenVDMCSVParser
from server.lib.openvdm import OpenVDM_API

RAW_COLS = ['date_time','data'] # OpenRVDAS style
# RAW_COLS = ['date','time','data'] # SCS style
PROC_COLUMNS = ['date_time','conductivity','water_temp_1','salinity','water_temp_2', 'fluorescence','sound_velocity']

ROUNDING = {
    'conductivity': 5,
    'water_temp_1': 4,
    'salinity': 4,
    'water_temp_2': 4,
    'fluorescence': 5,
    'sound_velocity': 5
}

MIN_DEPTH = 0

MAX_DELTA_T = pd.Timedelta('10 seconds')

DEFAULT_TIME_FORMAT = "%Y-%m-%dT%H:%M:%S.%fZ" # ISO8601 Format, OpenRVDAS style
# DEFAULT_TIME_FORMAT = "%m/%d/%Y %H:%M:%S.%f" # SCS style


class SBE21TSGParser(OpenVDMCSVParser):

    def __init__(self, start_dt=None, stop_dt=None, time_format=DEFAULT_TIME_FORMAT, use_openvdm_api=True):
        super().__init__(start_dt=start_dt, stop_dt=stop_dt)
        self.raw_cols = RAW_COLS
        self.proc_cols = PROC_COLS
        self.time_format = time_format
        self.openvdm = OpenVDM_API() if use_openvdm_api else None


    def process_file(self, filePath):

        raw_into_df = { value: [] for key, value in enumerate(self.proc_cols) }

        logging.debug("Parsing data file...")
        errors = []
        try:
            with open(filePath, 'r') as csvfile:
                reader = csv.DictReader(csvfile, self.raw_cols)

                for lineno, line in enumerate(reader):

                    try:
                        date_time = line['date_time'] # OpenRVDAS style
                        #date_time = ' '.join([line['date'], line['time']]) # SCS style

                        data_cont,data_temp_1,data_sal,data_temp_2,data_fluoro,data_sv =  line['data'].split()

                        conductivity = float(data_cont)
                        water_temp_1 = float(data_temp_1)
                        salinity = float(data_sal)
                        water_temp_2 = float(data_temp_2)
                        fluorescence = float(data_fluoro)
                        sound_velocity = float(data_sv)                        

                    except Exception as err:
                        errors.append(lineno)
                        logging.warning("Parsing error encountered on line {}".format(lineno))
                        logging.debug(line)
                        logging.debug(str(err))

                    else:
                        raw_into_df['date_time'].append(date_time)
                        raw_into_df['conductivity'].append(conductivity)
                        raw_into_df['water_temp_1'].append(water_temp_1)
                        raw_into_df['salinity'].append(salinity)
                        raw_into_df['water_temp_2'].append(water_temp_2)
                        raw_into_df['fluorescence'].append(fluorescence)
                        raw_into_df['sound_velocity'].append(sound_velocity)

        except Exception as err:
            logging.error("Problem accessing input file: {}".format(filePath))
            logging.error(str(err))
            return None

        logging.debug("Finished parsing data file")
        
        # If no data ingested from file, quit
        if len(raw_into_df['date_time']) == 0:
            logging.warning("Dataframe is empty... quitting")
            return None

        # Build DataFrame
        logging.debug("Building dataframe from parsed data...")
        df_proc = pd.DataFrame(raw_into_df)

        # Convert Date/time column to datetime objects
        logging.debug("Converting data_time to datetime datatype...")
        
        df_proc['date_time'] = pd.to_datetime(df_proc['date_time'], format=self.time_format)

        # Optionally crop data by start/stop times
        if self.start_dt or self.stop_dt:
            logging.debug("Cropping data...")

            df_proc = self.crop_data(df_proc)

        # If the crop operation emptied the dataframe, quit
        if df_proc.shape[0] == 0:
            logging.warning("Cropped dataframe is empty... quitting")
            return None

        # Calculate deltaT column
        logging.debug('Building deltaT column...')
        df_proc = df_proc.join(df_proc['date_time'].diff().to_frame(name='deltaT'))

        logging.debug("Tabulating statistics...")
        self.add_row_validity_stat([len(df_proc), len(errors)])
        self.add_time_bounds_stat([df_proc['date_time'].min(), df_proc['date_time'].max()])
        self.add_bounds_stat([round(df_proc['deltaT'].min().total_seconds(),3), round(df_proc['deltaT'].max().total_seconds(),3)], 'DeltaT Bounds', 'seconds')
        self.add_value_validity_stat([len(df_proc[(df_proc['deltaT'] <= MAX_DELTA_T)]),len(df_proc[(df_proc['deltaT'] > MAX_DELTA_T)])], 'DeltaT Validity')
        self.add_bounds_stat([round(df_proc['conductivity'].min(),5), round(df_proc['conductivity'].max(),5)], 'Conductivity', 'S/m')
        self.add_bounds_stat([round(df_proc['water_temp_1'].min(),4), round(df_proc['water_temp_1'].max(),4)], 'Water Temp 1', 'C')
        self.add_bounds_stat([round(df_proc['salinity'].min(),4), round(df_proc['salinity'].max(),4)], 'Salinity', 'PSU')
        self.add_bounds_stat([round(df_proc['water_temp_2'].min(),4), round(df_proc['water_temp_2'].max(),4)], 'Water Temp 2', 'C')
        self.add_bounds_stat([round(df_proc['fluorescence'].min(),5), round(df_proc['fluorescence'].max(),5)], 'Fluorescence', 'mg/m^3')
        self.add_bounds_stat([round(df_proc['sound_velocity'].min(),5), round(df_proc['sound_velocity'].max(),5)], 'Sound Velocity', 'm/s')
        
        logging.debug("Running quality tests...")
        # % of bad rows in datafile
        error_rate = len(errors) / (len(df_proc) + len(errors))
        if error_rate > .25:
            self.add_quality_test_failed("Rows")
        elif error_rate > .10:
            self.add_quality_test_warning("Rows")
        else:
            self.add_quality_test_passed("Rows")

        # % of time gaps in data
        error_rate = len(df_proc[(df_proc['deltaT'] > MAX_DELTA_T)]) / len(df_proc)
        if error_rate > .25:
            self.add_quality_test_failed("DeltaT")
        elif error_rate > .10:
            self.add_quality_test_warning("DeltaT")
        else:
            self.add_quality_test_passed("DeltaT")

        # set index
        logging.debug('Setting index...')
        df_proc = df_proc.set_index('date_time')

        # resample data
        logging.debug("Resampling data...")
        df_proc = self.resample_data(df_proc)

        # round data
        logging.debug("Rounding data: {}".format(ROUNDING))
        df_proc = self.round_data(df_proc, ROUNDING)

        # split data where there are gaps
        logging.debug("Building visualization data...")

        visualizerDataObj = {'data':[], 'unit':'', 'label':''}
        visualizerDataObj['data'] = json.loads(df_crop[['date_time','water_temp_1']].to_json(orient='values'))
        visualizerDataObj['unit'] = 'C'
        visualizerDataObj['label'] = 'Water Temp 1'
        # output['visualizerData'].append(copy.deepcopy(visualizerDataObj))
        self.add_visualization_data(visualizerDataObj)

        visualizerDataObj['data'] = json.loads(df_crop[['date_time','conductivity']].to_json(orient='values'))
        visualizerDataObj['unit'] = 'S/m'
        visualizerDataObj['label'] = 'Conductivity'
        # output['visualizerData'].append(copy.deepcopy(visualizerDataObj))
        self.add_visualization_data(visualizerDataObj)

        visualizerDataObj['data'] = json.loads(df_crop[['date_time','salinity']].to_json(orient='values'))
        visualizerDataObj['unit'] = 'PSU'
        visualizerDataObj['label'] = 'Salinity'
        # output['visualizerData'].append(copy.deepcopy(visualizerDataObj))
        self.add_visualization_data(visualizerDataObj)

        visualizerDataObj['data'] = json.loads(df_crop[['date_time','water_temp_2']].to_json(orient='values'))
        visualizerDataObj['unit'] = 'C'
        visualizerDataObj['label'] = 'Water Temp 2'
        # output['visualizerData'].append(copy.deepcopy(visualizerDataObj))
        self.add_visualization_data(visualizerDataObj)

        visualizerDataObj['data'] = json.loads(df_crop[['date_time','fluorescence']].to_json(orient='values'))
        visualizerDataObj['unit'] = 'mg/m^3'
        visualizerDataObj['label'] = 'Fluorescence'
        # output['visualizerData'].append(copy.deepcopy(visualizerDataObj))
        self.add_visualization_data(visualizerDataObj)

        visualizerDataObj['data'] = json.loads(df_crop[['date_time','sound_velocity']].to_json(orient='values'))
        visualizerDataObj['unit'] = 'm/s'
        visualizerDataObj['label'] = 'Sound Velocity'
        # output['visualizerData'].append(copy.deepcopy(visualizerDataObj))
        self.add_visualization_data(visualizerDataObj)

        # send message about errors encountered to OpenVDM
        if self.openvdm is not None:
            self.openvdm.sendMsg('Parsing Error', 'Error(s) parsing datafile {} on row(s): {}'.format(filePath, ', '.join([str(error) for error in errors])))


# -------------------------------------------------------------------------------------
# Required python code for running the script as a stand-alone utility
# -------------------------------------------------------------------------------------
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Parse SBE21 TSG sensor data')
    parser.add_argument('-v', '--verbosity', dest='verbosity',
                        default=0, action='count',
                        help='Increase output verbosity')
    parser.add_argument('--timeFormat', default=DEFAULT_TIME_FORMAT,
                        help='timestamp format, default: %(default)')
    parser.add_argument('--startDT', default=None,
                        type=lambda s: datetime.strptime(s, '%Y-%m-%dT%H:%M:%S.%fZ'),
                        help=' crop start timestamp (iso8601)')
    parser.add_argument('--stopDT', default=None,
                        type=lambda s: datetime.strptime(s, '%Y-%m-%dT%H:%M:%S.%fZ'),
                        help=' crop stop timestamp (iso8601)')
    parser.add_argument('dataFile', metavar='dataFile',
                        help='the raw data file to process')

    parsed_args = parser.parse_args()

    ############################
    # Set up logging before we do any other argument parsing (so that we
    # can log problems with argument parsing).
    
    LOGGING_FORMAT = '%(asctime)-15s %(levelname)s - %(message)s'
    logging.basicConfig(format=LOGGING_FORMAT)

    LOG_LEVELS = {0: logging.WARNING, 1: logging.INFO, 2: logging.DEBUG}
    parsed_args.verbosity = min(parsed_args.verbosity, max(LOG_LEVELS))
    logging.getLogger().setLevel(LOG_LEVELS[parsed_args.verbosity])

    ovdm_parser = SBE21TSGParser(start_dt=parsed_args.startDT, stop_dt=parsed_args.stopDT, time_format=parsed_args.timeFormat)

    try:
        logging.info("Processing file: {}".format(parsed_args.dataFile))
        ovdm_parser.process_file(parsed_args.dataFile)
        print(ovdm_parser.toJSON())
        logging.info("Done!")
    except Exception as err:
        logging.error(str(err))
        raise err
        sys.exit(1)


# =================================================================================== #
#
#         FILE:  tsg_parser.py
#
#        USAGE:  tsg_parser.py [-h] [-c] <dataFile>
#
#  DESCRIPTION:  Parse the supplied CSV-formtted Thermosalinigraph file (w/ SCS formatted timestamp)
#                and return the json-formatted string used by OpenVDM as part of it's
#                Data dashboard. 
#
#      OPTIONS:  [-h] Return the help message.
#                [-c] Use CSVkit to clean the datafile prior to processing
#                <dataFile> Full or relative path of the data file to process.
#
# REQUIREMENTS:  python2.7, Python Modules: sys, os, argparse, json, pandas
#
#         BUGS:
#        NOTES:
#       AUTHOR:  Webb Pinner
#      COMPANY:  Capable Solutions
#      VERSION:  1.0
#      CREATED:  2016-08-29
#     REVISION:  2016-12-29
#
# LICENSE INFO:  Open Vessel Data Management v2.2 (OpenVDMv2)
#                Copyright (C) 2017 OceanDataRat.org
#
#        NOTES:  Requires Pandas v0.18 or higher
#
#    This program is free software: you can redistribute it and/or modify it under the
#    terms of the GNU General Public License as published by the Free Software
#    Foundation, either version 3 of the License, or (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful, but WITHOUT ANY
#    WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
#    PARTICULAR PURPOSE.  See the GNU General Public License for more details.
#
#    You should have received a copy of the GNU General Public License #    along with
#    this program.  If not, see <http://www.gnu.org/licenses/>.
#
# =================================================================================== #
from __future__ import print_function
import pandas as pd
import numpy as np
import json
import argparse
import subprocess
import tempfile
import sys
import copy
import os
import shutil
import csv
from itertools import (takewhile,repeat)

# visualizerDataObj = {'data':[], 'unit':'', 'label':''}
# statObj = {'statName':'', 'statUnit':'', 'statType':'', 'statData':[]}
# qualityTestObj = {"testName": "", "results": ""}


RAW_COLUMNS = ['date','time','data']
PROC_COLUMNS = ['date_time','Conductivity_(S/m)','Water_Temp_1_(C)','Salinity_(PSU)','Water_Temp_2_(C)', 'Fluorescence_(mg/m^3)','Sound_Velocity_(m/s)']
CROP_COLUMNS = ['date_time','Conductivity_(S/m)','Water_Temp_1_(C)','Salinity_(PSU)','Water_Temp_2_(C)', 'Fluorescence_(mg/m^3)','Sound_Velocity_(m/s)']

MAX_DELTA_T = pd.Timedelta('10 seconds')

RESAMPLE_INTERVAL = '1T' # 1 minute

DEBUG = False
CSVKIT = False

def debugPrint(*args, **kwargs):
    if DEBUG:
        errPrint(*args, **kwargs)

def errPrint(*args, **kwargs):
        print(*args, file=sys.stderr, **kwargs)


def rawincount(filename):
    f = open(filename, 'rb')
    bufgen = takewhile(lambda x: x, (f.read(1024*1024) for _ in repeat(None)))
    return sum( buf.count(b'\n') for buf in bufgen )

def csvCleanup(filepath):

    command = ['csvclean', filepath]
    errors = 0

    s = ' '
    debugPrint(s.join(command))

    proc = subprocess.Popen(command,stderr=subprocess.PIPE, stdout=subprocess.PIPE)
    out, err = proc.communicate()

    (dirname, basename) = os.path.split(filepath)

    debugPrint("Dirname:" + dirname)
    debugPrint("Basename:" + basename)

    outfile = os.path.join(dirname, os.path.splitext(basename)[0] + '_out.csv')
    errfile = os.path.join(dirname, os.path.splitext(basename)[0] + '_err.csv')

    debugPrint("Outfile: " + outfile)
    debugPrint("Errfile: " + errfile)

    if os.path.isfile(errfile):
        errors = rawincount(errfile)-1

    return (errors, outfile)


def parseFile(filePath):
    output = {}
    output['visualizerData'] = []
    output['qualityTests'] = []
    output['stats'] = []

    tmpdir = tempfile.mkdtemp()

    outfile = filePath
    errors = 0

    if CSVKIT:
        shutil.copy(filePath, tmpdir)
        (errors, outfile) = csvCleanup(os.path.join(tmpdir, os.path.basename(filePath)))
        debugPrint('Error: ', errors)

    debugPrint("Errors:", errors)

    rawIntoDf = {
        'date_time':[],
        'Water_Temp_1_(C)':[],
        'Conductivity_(S/m)':[],
        'Salinity_(PSU)':[],
        'Sound_Velocity_(m/s)':[],
        'Water_Temp_2_(C)':[],
                'Fluorescence_(mg/m^3)':[]
    }

    csvfile = open(outfile, 'r')
    reader = csv.DictReader( csvfile, RAW_COLUMNS)

    for line in reader:

        try:

            line_date_time = line['date'] + ' ' + line['time']
            line_cont,line_int_temp,line_sal,line_ext_temp,line_fluoro,line_sv =  line['data'].split()

            line_cont = float(line_cont)
            line_int_temp = float(line_int_temp)
            line_sal = float(line_sal)
            line_ext_temp = float(line_ext_temp)
            line_fluoro = float(line_fluoro)
            line_sv = float(line_sv)

        except:

            debugPrint('Parsing error: ',line['data'])
            #debugPrint(line['Water_Temp_1_(C)'].split('=')[1].lstrip(' '))
            #debugPrint(line['Conductivity_(S/m)'].split('=')[1].lstrip(' '))
            #debugPrint(line['Salinity_(PSU)'].split('=')[1].lstrip(' '))
            #debugPrint(line['Sound_Velocity_(m/s)'].split('=')[1].lstrip(' '))
            #debugPrint(line['Water_Temp_2_(C)'].split('=')[1].lstrip(' '))
            errors += 1

        else:
            rawIntoDf['date_time'].append(line_date_time)
            rawIntoDf['Water_Temp_1_(C)'].append(line_int_temp)
            rawIntoDf['Conductivity_(S/m)'].append(line_cont)
            rawIntoDf['Salinity_(PSU)'].append(line_sal)
            rawIntoDf['Sound_Velocity_(m/s)'].append(line_sv)
            rawIntoDf['Water_Temp_2_(C)'].append(line_ext_temp)
            rawIntoDf['Fluorescence_(mg/m^3)'].append(line_fluoro)

    shutil.rmtree(tmpdir)

    if len(rawIntoDf['date_time']) == 0:
        errPrint("No Input")
        return None

    df_proc = pd.DataFrame(rawIntoDf)

    df_proc['date_time'] = pd.to_datetime(df_proc['date_time'], infer_datetime_format=True)

    df_proc = df_proc.join(df_proc['date_time'].diff().to_frame(name='deltaT'))

    rowValidityStat = {'statName':'Row Validity', 'statType':'rowValidity', 'statData':[len(df_proc), errors]}
    output['stats'].append(rowValidityStat)

    intTempStat = {'statName': 'Water Temp 1 Bounds','statUnit': 'C', 'statType':'bounds', 'statData':[round(df_proc['Water_Temp_1_(C)'].min(),3), round(df_proc['Water_Temp_1_(C)'].max(),3)]}
    output['stats'].append(intTempStat)

    contStat = {'statName': 'Conductivity','statUnit': 'S/m', 'statType':'bounds', 'statData':[round(df_proc['Conductivity_(S/m)'].min(),3), round(df_proc['Conductivity_(S/m)'].max(),3)]}
    output['stats'].append(contStat)

    salStat = {'statName': 'Salinity','statUnit': 'PSU', 'statType':'bounds', 'statData':[round(df_proc['Salinity_(PSU)'].min(),3), round(df_proc['Salinity_(PSU)'].max(),3)]}
    output['stats'].append(salStat)

    svTempStat = {'statName': 'Sound Velocity','statUnit': 'm/s', 'statType':'bounds', 'statData':[round(df_proc['Sound_Velocity_(m/s)'].min(),3), round(df_proc['Sound_Velocity_(m/s)'].max(),3)]}
    output['stats'].append(svTempStat)

    extTempStat = {'statName': 'Water Temp 2 Bounds','statUnit': 'C', 'statType':'bounds', 'statData':[round(df_proc['Water_Temp_2_(C)'].min(),3), round(df_proc['Water_Temp_2_(C)'].max(),3)]}
    output['stats'].append(extTempStat)

    fluoroStat = {'statName': 'Fluorescence Bounds','statUnit': 'mg/m^3', 'statType':'bounds', 'statData':[round(df_proc['Fluorescence_(mg/m^3)'].min(),3), round(df_proc['Fluorescence_(mg/m^3)'].max(),3)]}
    output['stats'].append(fluoroStat)

    temporalStat = {'statName': 'Temporal Bounds','statUnit': 'seconds', 'statType':'timeBounds', 'statData':[df_proc.date_time.min().strftime('%s'), df_proc.date_time.max().strftime('%s')]}
    output['stats'].append(temporalStat)

    deltaTStat = {"statName": "Delta-T Bounds","statUnit": "seconds","statType": "bounds","statData": [round(df_proc.deltaT.min().total_seconds(),3), round(df_proc.deltaT.max().total_seconds(),3)]}
    output['stats'].append(deltaTStat)

    deltaTValidityStat = {'statName':'Temporal Validity', 'statType':'valueValidity', 'statData':[len(df_proc[(df_proc['deltaT'] <= MAX_DELTA_T)]),len(df_proc[(df_proc['deltaT'] > MAX_DELTA_T)])]}
    output['stats'].append(deltaTValidityStat)

    rowQualityTest = {"testName": "Rows", "results": "Passed"}
    if rowValidityStat['statData'][1] > 0:
        if rowValidityStat['statData'][1]/rowValidityStat['statData'][0] > .10:
            rowQualityTest['results'] = "Failed"
        else:
            rowQualityTest['results'] = "Warning"
    output['qualityTests'].append(rowQualityTest)

    deltaTQualityTest = {"testName": "DeltaT", "results": "Passed"}
    if deltaTValidityStat['statData'][1] > 0:
        if deltaTValidityStat['statData'][1]/len(df_proc) > .10:
            deltaTQualityTest['results'] = "Failed"
        else:
            deltaTQualityTest['results'] = "Warning"
    output['qualityTests'].append(deltaTQualityTest)

    df_crop = df_proc[CROP_COLUMNS]

    df_crop = df_crop.set_index('date_time')

    df_crop = df_crop.resample(RESAMPLE_INTERVAL, label='right', closed='right').mean()

    df_crop = df_crop.reset_index()

    decimals = pd.Series([5,4,4,4,5,5], index=['Conductivity_(S/m)','Water_Temp_1_(C)','Salinity_(PSU)','Water_Temp_2_(C)','Fluorescence_(mg/m^3)','Sound_Velocity_(m/s)'])
    df_crop = df_crop.round(decimals)

    visualizerDataObj = {'data':[], 'unit':'', 'label':''}

    visualizerDataObj['data'] = json.loads(df_crop[['date_time','Water_Temp_1_(C)']].to_json(orient='values'))
    visualizerDataObj['unit'] = 'C'
    visualizerDataObj['label'] = 'Water Temp 1'
    output['visualizerData'].append(copy.deepcopy(visualizerDataObj))

    visualizerDataObj['data'] = json.loads(df_crop[['date_time','Conductivity_(S/m)']].to_json(orient='values'))
    visualizerDataObj['unit'] = 'S/m'
    visualizerDataObj['label'] = 'Conductivity'
    output['visualizerData'].append(copy.deepcopy(visualizerDataObj))

    visualizerDataObj['data'] = json.loads(df_crop[['date_time','Salinity_(PSU)']].to_json(orient='values'))
    visualizerDataObj['unit'] = 'PSU'
    visualizerDataObj['label'] = 'Salinity'
    output['visualizerData'].append(copy.deepcopy(visualizerDataObj))

    visualizerDataObj['data'] = json.loads(df_crop[['date_time','Sound_Velocity_(m/s)']].to_json(orient='values'))
    visualizerDataObj['unit'] = 'm/s'
    visualizerDataObj['label'] = 'Sound Velocity'
    output['visualizerData'].append(copy.deepcopy(visualizerDataObj))

    visualizerDataObj['data'] = json.loads(df_crop[['date_time','Water_Temp_2_(C)']].to_json(orient='values'))
    visualizerDataObj['unit'] = 'C'
    visualizerDataObj['label'] = 'Water Temp 2'
    output['visualizerData'].append(copy.deepcopy(visualizerDataObj))

    visualizerDataObj['data'] = json.loads(df_crop[['date_time','Fluorescence_(mg/m^3)']].to_json(orient='values'))
    visualizerDataObj['unit'] = 'mg/m^3'
    visualizerDataObj['label'] = 'Fluorescence'
    output['visualizerData'].append(copy.deepcopy(visualizerDataObj))

    return output

# -------------------------------------------------------------------------------------
# Main function of the script should it be run as a stand-alone utility.
# -------------------------------------------------------------------------------------
def main(argv):
    
    parser = argparse.ArgumentParser(description='Parse TSG21 data')
    parser.add_argument('dataFile', metavar='dataFile', help='the raw data file to process')
    parser.add_argument('-d', '--debug', action='store_true', help=' display debug messages')
    parser.add_argument('-c', '--csvkit', action='store_true', help=' clean datafile using CSVKit')

    args = parser.parse_args()
    if args.debug:
        global DEBUG
        DEBUG = True
        debugPrint("Running in debug mode")

    if args.csvkit:
        global CSVKIT
        CSVKIT = True
        debugPrint("Using CSVKit to clean data file prior to processing")

    if not os.path.isfile(args.dataFile):
        sys.stderr.write('ERROR: File not found\n')
        sys.exit(1)
    
    jsonObj = parseFile(args.dataFile)
    if jsonObj:
        print(json.dumps(jsonObj))
        sys.exit(0)
    else:
        sys.exit(1)
            
# -------------------------------------------------------------------------------------
# Required python code for running the script as a stand-alone utility
# -------------------------------------------------------------------------------------
if __name__ == "__main__":
    main(sys.argv[1:])
